<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Part 1 ‚Äì The Strange History of Teaching Computers to Read</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="style.css">

  <!-- Theme colors:
       #f6eaaf (light yellow), #ead3c1 (soft peach), #941236 (deep maroon) -->
  <style>
    :root {
      --bg-main: #f6eaaf;
      --bg-card: #ffffff;
      --bg-soft: #ead3c1;
      --accent:  #941236;
      --text-main: #222222;
      --text-muted: #555555;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background:
        radial-gradient(circle at top left, #ffffff, var(--bg-main));
      color: var(--text-main);
      line-height: 1.7;
    }

    .page-wrapper {
      max-width: 1400px;
      margin: 0 auto;
      padding: 2.5rem 1.25rem 3.5rem;
    }

    /* Main layout: article + sidebar */
    .blog-layout {
      display: flex;
      gap: 2rem;
      align-items: flex-start;
    }

    .blog-card {
      background: var(--bg-card);
      border-radius: 1.25rem;
      box-shadow: 0 16px 40px rgba(0, 0, 0, 0.08);
      padding: 2.5rem 2.75rem;
      border-top: 6px solid var(--accent);
      flex: 3;
    }

    .blog-sidebar {
      flex: 1.2;
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
    }

    @media (max-width: 900px) {
      .blog-layout {
        flex-direction: column;
      }

      .blog-sidebar {
        width: 100%;
      }
    }

    @media (max-width: 768px) {
      .blog-card {
        padding: 1.75rem 1.5rem;
        border-radius: 1rem;
      }
    }

    .blog-meta {
      font-size: 0.85rem;
      text-transform: uppercase;
      letter-spacing: 0.12em;
      color: var(--text-muted);
      margin-bottom: 0.75rem;
    }

    .series-tag {
      display: inline-flex;
      align-items: center;
      gap: 0.4rem;
      padding: 0.25rem 0.7rem;
      border-radius: 999px;
      background: var(--bg-soft);
      color: var(--accent);
      font-size: 0.75rem;
      font-weight: 600;
      letter-spacing: 0.12em;
      text-transform: uppercase;
    }

    .series-tag-dot {
      width: 7px;
      height: 7px;
      border-radius: 999px;
      background: var(--accent);
    }

    h1 {
      font-size: 2.1rem;
      margin: 0.4rem 0 0.75rem;
      color: var(--accent);
      letter-spacing: 0.02em;
    }

    .blog-subtitle {
      font-size: 1rem;
      color: var(--text-muted);
      margin-bottom: 1.8rem;
    }

    h2 {
      font-size: 1.7rem;
      margin-top: 2.25rem;
      margin-bottom: 0.6rem;
      color: var(--accent);
    }

    h3 {
      font-size: 1.3rem;
      margin-top: 1.6rem;
      margin-bottom: 0.4rem;
      color: #7a0f29;
    }

    p {
      margin: 0.5rem 0 0.9rem;
      font-size: 1.2rem;
    }

    strong {
      color: #3a111c;
    }

    .emphasis-line {
      padding: 0.7rem 1rem;
      border-left: 4px solid var(--accent);
      background: #fff8e7;
      border-radius: 0.6rem;
      font-size: 1.2rem;
      margin: 1rem 0 1.4rem;
    }

    .timeline-callout {
      background: var(--bg-soft);
      border-radius: 0.9rem;
      padding: 1rem 1.1rem;
      margin: 1.4rem 0;
      font-size: 0.93rem;
    }

    .timeline-callout-title {
      font-weight: 600;
      color: var(--accent);
      margin-bottom: 0.35rem;
      text-transform: uppercase;
      font-size: 0.8rem;
      letter-spacing: 0.14em;
    }

    ul {
      padding-left: 1.3rem;
      margin: 0.25rem 0 1rem;
    }

    li {
      margin: 0.2rem 0;
      font-size: 1.2rem;
    }

    .muted {
      color: var(--text-muted);
    }

    .inline-question {
      font-style: italic;
      color: #4a222b;
    }

    .section-divider {
      margin: 2.2rem 0 1.8rem;
      height: 1px;
      border: none;
      background: linear-gradient(to right, transparent, #d7b2a3, transparent);
    }

    /* Sidebar cards + links */
    .sidebar-card {
      background: #fffdf7;
      border-radius: 1rem;
      padding: 1.1rem 1.1rem 1.2rem;
      box-shadow: 0 8px 20px rgba(0,0,0,0.04);
      border: 1px solid rgba(148, 18, 54, 0.08);
    }

    .sidebar-title {
      font-size: 1.1rem;
      margin: 0 0 0.75rem;
      color: var(--accent);
    }

    .sidebar-title-sm {
      font-size: 0.98rem;
      margin: 0 0 0.6rem;
      color: #7a0f29;
    }

    .sidebar-link {
      display: block;
      padding: 0.5rem 0.4rem;
      border-radius: 0.6rem;
      text-decoration: none;
      background: transparent;
      transition: background 0.18s ease, transform 0.12s ease;
    }

    .sidebar-link + .sidebar-link {
      margin-top: 0.15rem;
    }

    .sidebar-link:hover {
      background: rgba(234, 211, 193, 0.5);
      transform: translateX(2px);
    }

    .sidebar-link-title {
      font-size: 0.9rem;
      font-weight: 600;
      color: #3a111c;
    }

    .sidebar-link-meta {
      font-size: 0.75rem;
      color: var(--text-muted);
    }

    .sidebar-link-title-sm {
      font-size: 0.88rem;
      font-weight: 500;
      color: #3a111c;
    }

    .sidebar-empty {
      font-size: 0.85rem;
      color: var(--text-muted);
    }

    /* Image blocks inside article */
    .image-block {
      margin: 1.6rem 0 1.3rem;
    }

    .image-frame {
      width: 100%;
      max-width: 780px;
      height: 260px;
      margin: 0 auto;
      border-radius: 0.9rem;
      border: 2px dashed rgba(148, 18, 54, 0.35);
      background: linear-gradient(
        135deg,
        rgba(246, 234, 175, 0.5),
        rgba(234, 211, 193, 0.6)
      );
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: hidden;
      position: relative;
      cursor: zoom-in; 
    }

    .image-frame img {
      width: 100%;
      height: 100%;
      object-fit: contain;
      display: block;
    }

    .image-placeholder-text {
      font-size: 0.9rem;
      color: #5c2a33;
      text-align: center;
      padding: 0 1.5rem;
    }

    .image-placeholder-label {
      position: absolute;
      bottom: 10px;
      right: 12px;
      font-size: 0.7rem;
      text-transform: uppercase;
      letter-spacing: 0.14em;
      color: rgba(148, 18, 54, 0.8);
      background: rgba(255, 255, 255, 0.75);
      padding: 0.25rem 0.55rem;
      border-radius: 999px;
    }

    .image-caption {
      max-width: 780px;
      margin: 0.5rem auto 0.2rem;
      font-size: 0.9rem;
      color: var(--text-muted);
      text-align: center;
    }

    /* Image zoom modal */
.image-modal {
  position: fixed;
  inset: 0;
  background: rgba(0, 0, 0, 0.75);
  display: none;                /* hidden by default */
  align-items: center;
  justify-content: center;
  z-index: 9999;
}

.image-modal.open {
  display: flex;
}

.image-modal-inner {
  position: relative;
  max-width: 90vw;
  max-height: 90vh;
}

.image-modal-img {
  max-width: 100%;
  max-height: 100%;
  border-radius: 1rem;
  transform: scale(1.1);   
  transform-origin: center;
  box-shadow: 0 18px 45px rgba(0, 0, 0, 0.5);
  background: #ffffff;
}

.image-modal-caption {
  margin-top: 0.5rem;
  font-size: 0.9rem;
  color: #f6eaaf;
  text-align: center;
}

.image-modal-close {
  position: absolute;
  top: -10px;
  right: -10px;
  border: none;
  background: #ffffff;
  color: #941236;
  border-radius: 999px;
  width: 28px;
  height: 28px;
  font-size: 1.1rem;
  cursor: pointer;
  box-shadow: 0 4px 10px rgba(0,0,0,0.25);
}


    @media (max-width: 768px) {
      .image-frame {
        height: 210px;
      }
      .image-placeholder-text {
        font-size: 0.85rem;
        padding: 0 1rem;
      }
    }

    /* Comments section */
    .comments-section {
      margin-top: 3rem;
    }

    .comments-section h2 {
      font-size: 1.4rem;
      color: var(--accent);
      margin-bottom: 1rem;
    }
  </style>

  <!-- Optional: Giscus will be loaded at bottom; no config needed here -->
</head>

<!-- Image zoom modal -->
<div id="image-modal" class="image-modal" aria-hidden="true">
  <div class="image-modal-inner">
    <button class="image-modal-close" aria-label="Close image">&times;</button>
    <img id="image-modal-img" class="image-modal-img" alt="">
    <p id="image-modal-caption" class="image-modal-caption"></p>
  </div>
</div>

<body>
  <!-- NAVBAR -->
  <header class="site-header">
    <div class="nav-container">
      <a href="index.html" class="brand">
        <span class="brand-mark">AM</span>
        <span class="brand-text">Adithya MD</span>
      </a>
      <nav class="nav-links">
        <a href="index.html">Home</a>
        <a href="about.html">About</a>
        <a href="blogs.html">Blogs</a>
        <a href="projects.html">Projects</a>
        <a href="startup.html">Moisture Meter</a>

        <div class="dropdown">
          <button class="dropbtn">Teaching &amp; Outreach ‚ñæ</button>
          <div class="dropdown-content">
            <a href="teaching.html">Teaching Roles</a>
            <a href="workshops.html">Workshops</a>
            <a href="talks.html">Talks</a>
          </div>
        </div>

        <a href="contact.html">Contact</a>
      </nav>
    </div>
  </header>

  <div class="page-wrapper">
    <div class="blog-layout">

      <!-- MAIN ARTICLE -->
      <article class="blog-card"
               data-post-id="llm-part1"
               data-series-id="llm-first-principles">

        <div class="blog-meta">
          <span class="series-tag">
            <span class="series-tag-dot"></span>
            LLM from first principles
          </span>
        </div>

        <h1>Part&nbsp;1 &mdash; The Strange History of Teaching Computers to Read Anything at All</h1>
        <p class="blog-subtitle">
          A historically overloaded answer to a simple question:  
          <strong>why do we even need tokenisation?</strong>
        </p>

        <!-- SECTION 1 -->
        <h2>1. Before Tokenisation, Before Unicode, Before ASCII,  A World With No Words</h2>

        <p>
          Let‚Äôs wind the clock back to the late 1930s and 1940s. No ChatGPT. No browsers. No ‚Äúlog in with Google‚Äù. 
          The word ‚Äúcomputer‚Äù didn‚Äôt even mean a machine yet; it often meant a person (usually a very tired one) doing 
          calculations by hand.
        </p>

        <p>
          When the first electronic and electromechanical computers appeared machines like the 
          <strong>Harvard Mark&nbsp;I</strong> (1944), <strong>ENIAC</strong> (1946), and <strong>EDSAC</strong> (1949) 
          they lived in a world made of:
        </p>

        <ul>
          <li>spinning gears and mechanical relays,</li>
          <li>vacuum tubes that glowed ominously,</li>
          <li>paper tapes that rustled like long receipts,</li>
          <li>and a lot of nervous engineers hoping nothing explodes.</li>
        </ul>

        <!-- IMAGE 1: EARLY COMPUTER ROOM -->
        <div class="image-block">
          <div class="image-frame">
            <!-- Replace with a real image later, e.g.: -->
                 <img src="assets/LLM_Series/Blog1/ENIAC.jpg"
                      alt="Engineers operating an early mainframe computer with racks of vacuum tubes" >

            <div class="image-placeholder-label">Early computers</div>
          </div>
        </div>

        <p>
          These machines did <em>not</em> know what a ‚Äúletter‚Äù was. There was no concept of words, sentences, paragraphs, 
          or ‚ÄúDear Sir/Madam‚Äù. The entire design was aimed at one thing:
        </p>

        <p class="emphasis-line">
          <strong>Numbers.</strong> And how quickly you could add them, subtract them, and hurl them through chains of arithmetic operations.
        </p>

        <p>
          If early ENIAC had feelings (it didn‚Äôt), and you tried to feed it a poem, it would have stared back at you in binary confusion. 
          It had circuitry for addition, multiplication, table lookups, and control flow, not for adjectives, metaphors, or inline sarcasm.
        </p>

        <p class="inline-question">
          So how did we go from ‚Äúbomb trajectory tables‚Äù to ‚Äúwrite me a haiku about coffee in the style of a GPU manual‚Äù?
        </p>

        <p>
          To answer that, we have to back up even further, to a time before computers were even ‚Äúcomputers‚Äù.
        </p>

        <hr class="section-divider">

        <!-- SECTION 2 -->
        <h2>2. Telegraphs, Beeps, and the First Attempt at ‚ÄúTurning Letters Into Code‚Äù</h2>

        <p>
          Long before anyone built ENIAC, humans had already discovered a different kind of machine-mediated communication: 
          the <strong>telegraph</strong>. In the 1830s and 1840s, Samuel Morse and others were figuring out how to send 
          messages across wires using electric pulses.
        </p>

        <p>
          Enter <strong>Morse code</strong> (1840s). For the first time in history, we systematically assigned patterns to letters:
        </p>

        <ul>
          <li><code>A</code> ‚Üí <code>.-</code></li>
          <li><code>B</code> ‚Üí <code>-...</code></li>
          <li><code>C</code> ‚Üí <code>-.-.</code></li>
        </ul>

        <!-- IMAGE 2: TELEGRAPH / MORSE -->
        <div class="image-block">
          <div class="image-frame">
            <img src="assets/LLM_Series/Blog1/Morse_code.jpg"
                     alt="Old telegraph key and paper tape with Morse code dots and dashes"> 
   
            <div class="image-placeholder-label">Morse code</div>
          </div>
          <p class="image-caption">
            The first ‚Äúencoding‚Äù of letters into structured signals long before digital computers.
          </p>
        </div>

        <p>
          It wasn‚Äôt ‚Äúnumeric‚Äù yet, but the core idea was already there:
        </p>

        <p class="emphasis-line">
          <strong>Letters can be turned into structured signals</strong> that machines can transmit, as long as everyone agrees on the mapping.
        </p>

        <p>
          Then in the 1870s, √âmile Baudot came along with the <strong>Baudot code</strong>. This was huge: he moved from dots and dashes 
          to a <strong>5-bit fixed-length code</strong>. Every character was represented by exactly 5 bits, giving 32 possible symbols.
        </p>

        <p>
          By the early 1900s, teleprinters using Baudot-like codes were humming in newsrooms and offices. Text was being turned into 
          electrical patterns, printed back as characters at the other end.
        </p>

        <div class="timeline-callout">
          <div class="timeline-callout-title">Proto-tokenisation, but not quite</div>
          <p>
            These systems weren‚Äôt ‚Äútokenisation‚Äù in the ML sense, but philosophically they were an early statement of the same idea:
            <br><br>
            <strong>If you want machines to handle language, you must first map language to a finite set of machine-friendly codes.</strong>
          </p>
        </div>

        <p>
          So by the time electronic computers appeared, the telegraph world had already been assigning coded identities to letters
          for decades. Early computer engineers looked at that and thought:
        </p>

        <p class="inline-question">
          ‚ÄúWhy reinvent the wheel? Let‚Äôs just do something similar with bits.‚Äù
        </p>

        <hr class="section-divider">

        <!-- SECTION 3 -->
        <h2>3. Early Electronic Computers Copy the Idea ... And Make a Mess</h2>

        <p>
          When machines like the <strong>UNIVAC&nbsp;I</strong> (1951) and IBM mainframes started to appear, hardware designers borrowed 
          heavily from telegraph systems:
        </p>

        <ul>
          <li>Some machines used <strong>6-bit character codes</strong> (64 symbols).</li>
          <li>Some used <strong>5-bit</strong> codes, inspired by Baudot.</li>
          <li>Some had proprietary encodings based on what their vendor thought was a good idea that week.</li>
        </ul>

        <p>
          There was no Internet, but there were already networks, tapes, punched cards, and the general desire to exchange files.  
          The problem was: nobody agreed on what bit pattern meant what character.
        </p>

        <!-- IMAGE 3: PUNCHED CARDS / ENCODING CHAOS -->
        <div class="image-block">
          <div class="image-frame">
            <img src="assets/LLM_Series/Blog1/Punch_Tapes.jpg"
                     alt="Stack of punched cards representing early computer encodings"> 
            
            <div class="image-placeholder-label">Encoding chaos</div>
          </div>
          <p class="image-caption">
           Incompatible encodings scattered across vendors and machines.
          </p>
        </div>

        <p class="emphasis-line">
          A program written for one machine might print ‚ÄúHELLO‚Äù there and pure nonsense on another machine even if the bits were identical.
        </p>

        <p>
          This was like a world where every city had its own private alphabet, and books could not be read if you took them across the border.
        </p>

        <p>
          Meanwhile, more and more people wanted computers to handle:
        </p>

        <ul>
          <li>business letters,</li>
          <li>reports,</li>
          <li>scientific notes,</li>
          <li>program source code (which is also text!),</li>
          <li>and eventually, early forms of email.</li>
        </ul>

        <p>
          The tension kept building until the 1960s, when people finally said:  
          <strong>‚ÄúWe need a standard. A real one.‚Äù</strong>
        </p>

        <hr class="section-divider">

        <!-- SECTION 4 -->
        <h2>4. 1963: ASCII Tries to Bring Order to the Alphabet Chaos</h2>

        <p>
          In the early 1960s, the American Standards Association pulled together a committee. The mission:
        </p>

        <p class="emphasis-line">
          <strong>Create a standard character set that all computers can use to exchange basic text reliably.</strong>
        </p>

        <p>
          The result was <strong>ASCII</strong> (American Standard Code for Information Interchange), first published in 1963 and refined over the next few years.
        </p>

        <p>Its design embraced a few key ideas:</p>

        <ul>
          <li>Use <strong>7 bits per character</strong> ‚Üí 128 possible values.</li>
          <li>Cover:
            <ul>
              <li>uppercase A‚ÄìZ</li>
              <li>lowercase a‚Äìz</li>
              <li>digits 0‚Äì9</li>
              <li>basic punctuation</li>
              <li>control codes like newline, backspace, bell, etc.</li>
            </ul>
          </li>
        </ul>

        <p>
          A few iconic mappings:
        </p>

        <ul>
          <li><code>'A'</code> ‚Üí 65</li>
          <li><code>'a'</code> ‚Üí 97</li>
          <li><code>'0'</code> ‚Üí 48</li>
          <li><code>' '</code> (space) ‚Üí 32</li>
        </ul>

        <!-- IMAGE 4: ASCII TABLE -->
        <div class="image-block">
          <div class="image-frame">
            <img src="assets/LLM_Series/Blog1/ASCII.jpg"
                     alt="Partial ASCII table showing letters and their numeric codes"> 
            <
            <div class="image-placeholder-label">ASCII table</div>
          </div>
          <p class="image-caption">
            The first widely adopted, consistent mapping from characters to numbers.
          </p>
        </div>

        <p>
          ASCII was a huge success. It became the common language between devices, operating systems, and eventually early Internet protocols.
        </p>

        <div class="timeline-callout">
          <div class="timeline-callout-title">But here‚Äôs the catch</div>
          <p>
            ASCII solves <strong>representation</strong>, not <strong>meaning</strong>.  
            The fact that <code>'A'</code> is 65 and <code>'B'</code> is 66 is purely conventional.  
            To a computer, 65 and 66 are just integers with zero built-in semantics.
          </p>
        </div>

        <p>
          There is no sense in which 65 is ‚Äúnear‚Äù 66 in a linguistic way.  
          ASCII is basically a bilingual dictionary: human letter ‚Üî machine number. Nothing more.
        </p>

        <p>
          But once ASCII became popular, another problem appeared.
        </p>

        <p class="inline-question">
          What about the rest of the world?
        </p>

        <hr class="section-divider">

        <!-- SECTION 5 -->
        <h2>5. The Encoding Wars: When 8 Bits Weren‚Äôt Enough for the Planet</h2>

        <p>
          ASCII was created in the US, for English-speaking systems. As computing spread:
        </p>

        <ul>
          <li>Europe wanted accented letters like √©, √±, √∂.</li>
          <li>Russia wanted Cyrillic characters.</li>
          <li>East Asia needed thousands of Han characters.</li>
          <li>The Middle East needed right-to-left scripts like Arabic and Hebrew.</li>
        </ul>

        <p>
          The result was a wild explosion of ‚Äúextended ASCII‚Äù encodings and regional standards:
        </p>

        <ul>
          <li><strong>ISO-8859-1</strong> (Western Europe)</li>
          <li><strong>Windows-1252</strong> (a very influential Microsoft encoding)</li>
          <li><strong>Shift-JIS</strong> (Japanese)</li>
          <li><strong>Big5</strong> (Traditional Chinese)</li>
          <li><strong>EUC-KR</strong> (Korean)</li>
          <li><strong>KOI8-R</strong> (Cyrillic)</li>
        </ul>

        <p>
          Each of these encodings reused the same byte values (128‚Äì255) but mapped them to completely different characters.
        </p>

        <p class="emphasis-line">
          The exact same sequence of bytes could mean ‚Äúr√©sum√©‚Äù in one encoding and pure garbage in another.
        </p>

        <!-- IMAGE 5: MOJIBAKE -->
        <div class="image-block">
          <div class="image-frame">
            <img src="assets/LLM_Series/Blog1/Mojibake.jpeg"
                     alt="Text rendered incorrectly showing mojibake characters instead of accents"> 
            
            <div class="image-placeholder-label">Mojibake</div>
          </div>
          <p class="image-caption">
           How the same bytes can look perfectly fine in one encoding and cursed in another.
          </p>
        </div>

        <p>
          This gave birth to the infamous phenomenon called <strong>mojibake</strong>: text that appears as nonsense when interpreted in 
          the wrong encoding. You might see:
        </p>

        <p>
          <code>√É¬©√É¬ß√É¬±</code> instead of <code>√©√ß√±</code>,  
          or something equally cursed.
        </p>

        <p>
          On a technical level:
        </p>

        <ul>
          <li>The bytes are fine.</li>
          <li>The machine is fine.</li>
          <li>The problem is that the <em>mapping</em> from bytes to characters changed.</li>
        </ul>

        <p>
          Again, notice the pattern:
        </p>

        <p class="emphasis-line">
          The machine sees <strong>numbers</strong>. The humans see <strong>meaning</strong>.  
          If the agreed mapping changes, the meaning evaporates.
        </p>

        <p>
          By the late 1980s, this was clearly unsustainable. The world needed something more ambitious than ASCII or individual 8-bit hacks.
        </p>

        <hr class="section-divider">

        <!-- SECTION 6 -->
        <h2>6. Unicode ... One Code Space to Rule (Almost) Them All</h2>

        <p>
          In 1991, the <strong>Unicode Consortium</strong> proposed a radical idea:
        </p>

        <p class="emphasis-line">
          Give every character from every writing system a unique number, called a <strong>code point</strong>.
        </p>

        <p>
          Instead of dozens of incompatible encodings, have one grand, unified table:
        </p>

        <ul>
          <li><code>'A'</code> ‚Üí U+0041</li>
          <li><code>'√±'</code> ‚Üí U+00F1</li>
          <li><code>'Â≠ó'</code> ‚Üí U+5B57</li>
          <li><code>'‡ÆÖ'</code> ‚Üí U+0B85</li>
          <li><code>'üôÇ'</code> ‚Üí U+1F642</li>
        </ul>

        <!-- IMAGE 6: UNICODE MAP -->
        <div class="image-block">
          <div class="image-frame">
            <img src="assets/LLM_Series/Blog1/Unicode.jpg"
                     alt="World map overlaid with sample Unicode characters from various scripts">
           
            <div class="image-placeholder-label">Unicode world</div>
          </div>
          <p class="image-caption">
           Unicode as a single code space unifying writing systems across the world.
          </p>
        </div>

        <p>
          Unicode wasn‚Äôt about English. It was about:
        </p>

        <ul>
          <li>modern languages,</li>
          <li>historic scripts,</li>
          <li>emojis (added later, but now very important!),</li>
          <li>mathematical symbols, currency signs, musical symbols, and more.</li>
        </ul>

        <p>
          However, code points are abstract numbers. They still needed to be stored as bytes. That‚Äôs where encodings like:
        </p>

        <ul>
          <li><strong>UTF-8</strong> (variable-length, ASCII-compatible),</li>
          <li><strong>UTF-16</strong>,</li>
          <li><strong>UTF-32</strong></li>
        </ul>

        <p>
          come in. Of these, UTF-8 became the superstar: by the 2010s, the vast majority of the web was using UTF-8.
        </p>

        <div class="timeline-callout">
          <div class="timeline-callout-title">Unicode‚Äôs achievement</div>
          <p>
            Unicode and UTF-8 solved <strong>coverage</strong> and <strong>interoperability</strong>.  
            For the first time, a single email or web page could mix English, Hindi, Japanese, Arabic, and emojis without 
            everything collapsing into mojibake.
          </p>
        </div>

        <p>
          But for our LLM story, there is a painful truth we must underline:
        </p>

        <p class="emphasis-line">
          Unicode gives numbers to symbols, but it still does <strong>not</strong> give numbers to <em>meaning</em>.
        </p>

        <p>
          To a machine:
        </p>

        <ul>
          <li>U+0041, U+0B85, U+1F642 are just different integers.</li>
          <li>There is no built-in concept that ‚Äúcat‚Äù and ‚Äúdog‚Äù are related, or that ‚Äúrun‚Äù and ‚Äúrunning‚Äù share structure.</li>
        </ul>

        <hr class="section-divider">

        <!-- SECTION 7 -->
        <h2>7. Why ‚ÄúText as Numbers‚Äù Is Not Enough for Machine Learning</h2>

        <p>
          At this point in history, we have:
        </p>

        <ul>
          <li>ASCII ‚Üí numbers for English characters.</li>
          <li>Unicode ‚Üí numbers for almost every character humans use.</li>
          <li>UTF-8 ‚Üí a practical way to store and transmit those numbers as bytes.</li>
        </ul>

        <p>
          So technically, we already have a ‚Äútext ‚Üí numbers‚Äù pipeline.  
          But from an ML perspective, it‚Äôs a disaster.
        </p>

        <p>Take the words:</p>

        <ul>
          <li><code>cat</code> ‚Üí <code>['c','a','t']</code> ‚Üí code points [99, 97, 116]</li>
          <li><code>dog</code> ‚Üí <code>['d','o','g']</code> ‚Üí code points [100, 111, 103]</li>
        </ul>

        <p>
          To a human:
        </p>

        <ul>
          <li>Both are animals.</li>
          <li>Both are short, common nouns.</li>
          <li>Both appear in beginner English textbooks and children‚Äôs stories.</li>
        </ul>

        <p>
          To a model that only sees Unicode numbers:
        </p>

        <ul>
          <li>[99, 97, 116] and [100, 111, 103] are just unrelated integer sequences.</li>
          <li>There is no natural geometry where they are ‚Äúclose‚Äù.</li>
          <li>There is nothing that encodes ‚Äúthese belong to the same category of thing‚Äù.</li>
        </ul>

        <p>
          Even worse:
        </p>

        <ul>
          <li><code>bank</code> (river bank) and <code>bank</code> (financial institution) have the <em>same</em> characters.</li>
          <li>The Unicode representation cannot distinguish them at all; context is needed.</li>
        </ul>

        <p>
          So yes, we‚Äôve succeeded in turning text into numbers. But those numbers are:
        </p>

        <ul>
          <li>arbitrary,</li>
          <li>discrete,</li>
          <li>and almost completely useless as a basis for building a language model.</li>
        </ul>

        <p class="emphasis-line">
          It‚Äôs like trying to understand music by only looking at the file size of MP3s. Technically a number, practically useless for meaning.
        </p>

        <hr class="section-divider">

        <!-- SECTION 8 -->
        <h2>8. The Philosophical Jump: From ‚ÄúCharacters‚Äù to ‚ÄúTokens‚Äù</h2>

        <p>
          At this stage, the story shifts from <strong>systems engineering</strong> to <strong>machine learning</strong>.
        </p>

        <p>
          ASCII and Unicode answered:
        </p>

        <p class="emphasis-line">
          <strong>‚ÄúHow do we represent characters consistently across machines?‚Äù</strong>
        </p>

        <p>
          But if we want models that can actually learn and generalise, we need to answer a different question:
        </p>

        <p class="emphasis-line">
          <strong>‚ÄúWhat are the basic units of text that our model should see, and how should we map those units to numbers?‚Äù</strong>
        </p>

        <p>
          That is the job of <strong>tokenisation</strong>.
        </p>

        <p>
          Tokenisation sits on top of Unicode and says:
        </p>

        <ul>
          <li>Don‚Äôt just think in terms of individual characters.</li>
          <li>Don‚Äôt jump directly to whole words either (too many words, too many edge cases).</li>
          <li>Instead, break text into <strong>tokens</strong> &mdash; pieces that balance:
            <ul>
              <li>frequency,</li>
              <li>expressiveness,</li>
              <li>and compactness.</li>
            </ul>
          </li>
        </ul>

        <p>
          These tokens might be:
        </p>

        <ul>
          <li>whole words (<code>cat</code>, <code>running</code>),</li>
          <li>subwords (<code>run</code>, <code>##ning</code>),</li>
          <li>or even character-like fragments (for very rare or complex text).</li>
        </ul>

        <p>
          Crucially, token IDs are assigned not by historical accident (like ASCII) or linguistic politics (like Unicode), but by:
        </p>

        <ul>
          <li>how often they occur in real text,</li>
          <li>how useful they are for compressing text,</li>
          <li>and how well they help the model learn patterns.</li>
        </ul>

        <p class="emphasis-line">
          Tokenisation is the first layer of numbers that is designed explicitly for <strong>learning</strong>, not just for <strong>storage</strong>.
        </p>

        <p>
          This is a huge conceptual shift:
        </p>

        <ul>
          <li>ASCII/Unicode: numbers for symbols.</li>
          <li>Tokenisation: numbers for <strong>units of meaning or usage</strong>.</li>
        </ul>

        <hr class="section-divider">

        <!-- SECTION 9 -->
        <h2>9. What This First Part of the Series Has Really Been About</h2>

        <p>
          On the surface, this chapter looked like a history lesson about telegraphs, ASCII, Unicode, and encodings.
        </p>

        <p>
          But underneath, it‚Äôs been quietly building one core insight:
        </p>

        <p class="emphasis-line">
          <strong>‚ÄúText as numbers‚Äù is not a new idea.  
          What‚Äôs new &mdash; and absolutely essential for LLMs &mdash; is giving those numbers <em>structure</em> that a model can learn from.</strong>
        </p>

        <p>
          The journey so far:
        </p>

        <ul>
          <li>Telegraph &amp; Morse ‚Üí map letters to dots and dashes.</li>
          <li>Baudot code ‚Üí fixed-length bit patterns for characters.</li>
          <li>Early computers ‚Üí messy, incompatible encodings.</li>
          <li>ASCII (1963) ‚Üí standard 7-bit English character set.</li>
          <li>Encoding wars (1970s‚Äì80s) ‚Üí dozens of clashing ‚Äúextended ASCII‚Äù sets.</li>
          <li>Unicode (1991) ‚Üí one code space for almost every character on Earth.</li>
          <li>UTF-8 (1990s+) ‚Üí a practical way to store and transmit Unicode.</li>
          <li>Modern ML ‚Üí needs something beyond ‚Äúcharacter = integer‚Äù.</li>
          <li>Tokenisation ‚Üí defines machine-friendly units of text that models can actually learn from.</li>
        </ul>

        <p>
          Everything up to Unicode is about <strong>getting text into the machine</strong>.  
          Tokenisation is the start of <strong>teaching the machine what to do with it</strong>.
        </p>

        <p class="muted">
          For now, it‚Äôs enough to remember:  
          <strong>computers have been turning text into numbers for over a century.</strong>  
          Tokenisation is where we finally start turning those numbers into something a model can learn from.
        </p>

        <!-- COMMENTS SECTION -->
        <hr class="section-divider">

        <section id="comments" class="comments-section">
          <h2>Comments</h2>

          <!-- Giscus: replace data-* values with actual ones from https://giscus.app -->
          <script src="https://giscus.app/client.js"
                  data-repo="YOUR_USERNAME/YOUR_REPO"
                  data-repo-id="YOUR_REPO_ID"
                  data-category="Blog Comments"
                  data-category-id="YOUR_CATEGORY_ID"
                  data-mapping="pathname"
                  data-strict="0"
                  data-reactions-enabled="1"
                  data-emit-metadata="0"
                  data-input-position="bottom"
                  data-theme="light"
                  data-lang="en"
                  crossorigin="anonymous"
                  async>
          </script>
        </section>

      </article>

      <!-- SIDEBAR -->
      <aside class="blog-sidebar">
        <div class="sidebar-card">
          <h2 class="sidebar-title">More in this series</h2>
          <div id="series-posts"></div>
        </div>

        <div class="sidebar-card">
          <h3 class="sidebar-title-sm">Other recent posts</h3>
          <div id="recent-posts"></div>
        </div>
      </aside>

    </div>
  </div>

  <!-- Dynamic sidebar data + logic -->
  <script src="/posts.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      if (typeof BLOG_POSTS === "undefined") return;

      const articleEl = document.querySelector(".blog-card");
      if (!articleEl) return;

      const currentId = articleEl.dataset.postId;
      const currentSeriesId = articleEl.dataset.seriesId;

      const currentPost = BLOG_POSTS.find(p => p.id === currentId);
      if (!currentPost) return;

      const sameSeries = BLOG_POSTS
        .filter(p => p.seriesId === currentSeriesId && p.id !== currentId)
        .sort((a, b) => (a.part || 0) - (b.part || 0));

      const recent = BLOG_POSTS
        .filter(p => p.id !== currentId)
        .sort((a, b) => new Date(b.date) - new Date(a.date))
        .slice(0, 4);

      const seriesContainer = document.getElementById("series-posts");
      const recentContainer = document.getElementById("recent-posts");

      if (sameSeries.length === 0) {
        seriesContainer.innerHTML =
          '<p class="sidebar-empty">More parts in this series are on the way.</p>';
      } else {
        seriesContainer.innerHTML = sameSeries.map(p => `
          <a class="sidebar-link" href="${p.url}">
            <div class="sidebar-link-title">
              Part ${p.part}: ${p.title.replace(/^Part\\s*\\d+\\s*[‚Äì-]\\s*/, "")}
            </div>
            <div class="sidebar-link-meta">
              ${p.date}
            </div>
          </a>
        `).join("");
      }

      recentContainer.innerHTML = recent.map(p => `
        <a class="sidebar-link" href="${p.url}">
          <div class="sidebar-link-title-sm">${p.title}</div>
          <div class="sidebar-link-meta">${p.date}</div>
        </a>
      `).join("");
    });
  </script>

  <script>
  document.addEventListener("DOMContentLoaded", function () {
    // Lightbox / image zoom logic
    const modal = document.getElementById("image-modal");
    const modalImg = document.getElementById("image-modal-img");
    const modalCaption = document.getElementById("image-modal-caption");
    const modalClose = document.querySelector(".image-modal-close");

    if (!modal || !modalImg || !modalCaption || !modalClose) return;

    // Any <img> inside .image-frame becomes zoomable
    document.querySelectorAll(".image-frame img").forEach(function (img) {
      img.style.cursor = "zoom-in";
      img.addEventListener("click", function () {
        modalImg.src = img.src;
        modalImg.alt = img.alt || "";

        // Use the nearest .image-caption if available
        const captionEl = img.closest(".image-block")?.querySelector(".image-caption");
        modalCaption.textContent = captionEl
          ? captionEl.textContent.trim()
          : (img.alt || "");

        modal.classList.add("open");
        modal.setAttribute("aria-hidden", "false");
      });
    });

    function closeModal() {
      modal.classList.remove("open");
      modal.setAttribute("aria-hidden", "true");
      modalImg.src = "";
      modalCaption.textContent = "";
    }

    modalClose.addEventListener("click", closeModal);

    // Click on dark background closes too
    modal.addEventListener("click", function (e) {
      if (e.target === modal) {
        closeModal();
      }
    });

    // ESC key closes
    document.addEventListener("keydown", function (e) {
      if (e.key === "Escape" && modal.classList.contains("open")) {
        closeModal();
      }
    });
  });
</script>


</body>
</html>
